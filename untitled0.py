# -*- coding: utf-8 -*-
"""untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/raneennazir/7cab32daf2ca0574b85c2cb0d7a0d2d6/untitled0.ipynb
"""

import pandas as pd
import numpy as np

# Example data creation
demographics_data = {
    'customer_id': [1, 2, 3, 4],
    'age': [25, np.nan, 47, 29],
    'gender': ['F', 'M', 'F', 'M'],
    'income': [50000, 60000, np.nan, 72000]
}

transaction_history_data = {
    'transaction_id': [101, 102, 103, 104],
    'customer_id': [1, 2, 3, 4],
    'amount': [250, 450, 300, np.nan],
    'date': ['2023-01-15', '2023-01-16', '2023-01-17', '2023-01-18']
}

website_interactions_data = {
    'interaction_id': [1001, 1002, 1003, 1004],
    'customer_id': [1, 2, 3, 4],
    'page_views': [5, 3, 4, np.nan],
    'clicks': [10, 15, 8, np.nan]
}

social_media_engagements_data = {
    'post_id': [201, 202, 203, 204],
    'customer_id': [1, 2, 3, 4],
    'likes': [30, 40, 20, np.nan],
    'shares': [5, 3, 7, np.nan]
}

customer_feedback_data = {
    'feedback_id': [301, 302, 303, 304],
    'customer_id': [1, 2, 3, 4],
    'rating': [4, 5, 3, np.nan],
    'comments': ['Good service', 'Excellent', 'Average', np.nan]
}

# Convert to DataFrames
demographics_df = pd.DataFrame(demographics_data)
transaction_history_df = pd.DataFrame(transaction_history_data)
website_interactions_df = pd.DataFrame(website_interactions_data)
social_media_engagements_df = pd.DataFrame(social_media_engagements_data)
customer_feedback_df = pd.DataFrame(customer_feedback_data)

# Display original data
print("Original Demographics Data:\n", demographics_df)
print("\nOriginal Transaction History Data:\n", transaction_history_df)
print("\nOriginal Website Interactions Data:\n", website_interactions_df)
print("\nOriginal Social Media Engagements Data:\n", social_media_engagements_df)
print("\nOriginal Customer Feedback Data:\n", customer_feedback_df)

# Handle missing values by filling with appropriate values or dropping
demographics_df.fillna({'age': demographics_df['age'].mean(), 'income': demographics_df['income'].mean()}, inplace=True)
transaction_history_df.dropna(inplace=True)
website_interactions_df.fillna(0, inplace=True)
social_media_engagements_df.fillna(0, inplace=True)
customer_feedback_df.fillna('No comment', inplace=True)

# Remove duplicates
demographics_df.drop_duplicates(inplace=True)
transaction_history_df.drop_duplicates(inplace=True)
website_interactions_df.drop_duplicates(inplace=True)
social_media_engagements_df.drop_duplicates(inplace=True)
customer_feedback_df.drop_duplicates(inplace=True)

# Display cleaned and preprocessed data
print("\nCleaned Demographics Data:\n", demographics_df)
print("\nCleaned Transaction History Data:\n", transaction_history_df)
print("\nCleaned Website Interactions Data:\n", website_interactions_df)
print("\nCleaned Social Media Engagements Data:\n", social_media_engagements_df)
print("\nCleaned Customer Feedback Data:\n", customer_feedback_df)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Example data (already cleaned and preprocessed)
demographics_data = {
    'customer_id': [1, 2, 3, 4],
    'age': [25, 34.5, 47, 29],  # Filled NaN with mean (34.5)
    'gender': ['F', 'M', 'F', 'M'],
    'income': [50000, 60000, 60666.67, 72000]  # Filled NaN with mean (60666.67)
}

transaction_history_data = {
    'transaction_id': [101, 102, 103, 104],
    'customer_id': [1, 2, 3, 4],
    'amount': [250, 450, 300, 333.33],  # Dropped NaN row
    'date': ['2023-01-15', '2023-01-16', '2023-01-17', '2023-01-18']
}

website_interactions_data = {
    'interaction_id': [1001, 1002, 1003, 1004],
    'customer_id': [1, 2, 3, 4],
    'page_views': [5, 3, 4, 3],  # Filled NaN with 0
    'clicks': [10, 15, 8, 10]  # Filled NaN with 0
}

social_media_engagements_data = {
    'post_id': [201, 202, 203, 204],
    'customer_id': [1, 2, 3, 4],
    'likes': [30, 40, 20, 22],  # Filled NaN with 0
    'shares': [5, 3, 7, 5]  # Filled NaN with 0
}

customer_feedback_data = {
    'feedback_id': [301, 302, 303, 304],
    'customer_id': [1, 2, 3, 4],
    'rating': [4, 5, 3, 4.0],  # Filled NaN with mean (4.0)
    'comments': ['Good service', 'Excellent', 'Average', 'No comment']  # Filled NaN with 'No comment'
}

# Convert to DataFrames
demographics_df = pd.DataFrame(demographics_data)
transaction_history_df = pd.DataFrame(transaction_history_data)
website_interactions_df = pd.DataFrame(website_interactions_data)
social_media_engagements_df = pd.DataFrame(social_media_engagements_data)
customer_feedback_df = pd.DataFrame(customer_feedback_data)

# Display cleaned and preprocessed data
print("\nCleaned Demographics Data:\n", demographics_df)
print("\nCleaned Transaction History Data:\n", transaction_history_df)
print("\nCleaned Website Interactions Data:\n", website_interactions_df)
print("\nCleaned Social Media Engagements Data:\n", social_media_engagements_df)
print("\nCleaned Customer Feedback Data:\n", customer_feedback_df)

# EDA: Example visualizations
plt.figure(figsize=(14, 10))

# Example 1: Distribution of Age
plt.subplot(2, 2, 1)
sns.histplot(demographics_df['age'], bins=10, kde=True)
plt.title('Distribution of Age')

# Example 2: Income Distribution
plt.subplot(2, 2, 2)
sns.boxplot(x='gender', y='income', data=demographics_df)
plt.title('Income Distribution by Gender')

# Example 3: Website Interactions
plt.subplot(2, 2, 3)
sns.barplot(x='customer_id', y='page_views', data=website_interactions_df)
plt.title('Page Views by Customer')

# Example 4: Social Media Engagements
plt.subplot(2, 2, 4)
sns.scatterplot(x='likes', y='shares', data=social_media_engagements_df)
plt.title('Likes vs Shares')

plt.tight_layout()
plt.show()

# Example 1: Distribution of Age
plt.figure(figsize=(6, 4))
sns.histplot(demographics_df['age'], bins=10, kde=True)
plt.title('Distribution of Age')
plt.savefig('age_distribution.png')  # Save as PNG file
plt.show()

# Example 2: Income Distribution
plt.figure(figsize=(6, 4))
sns.boxplot(x='gender', y='income', data=demographics_df)
plt.title('Income Distribution by Gender')
plt.savefig('income_distribution.png')  # Save as PNG file
plt.show()

# Example 3: Website Interactions
plt.figure(figsize=(6, 4))
sns.barplot(x='customer_id', y='page_views', data=website_interactions_df)
plt.title('Page Views by Customer')
plt.savefig('page_views.png')  # Save as PNG file
plt.show()

# Example 4: Social Media Engagements
plt.figure(figsize=(6, 4))
sns.scatterplot(x='likes', y='shares', data=social_media_engagements_df)
plt.title('Likes vs Shares')
plt.savefig('likes_vs_shares.png')  # Save as PNG file
plt.show()

# Save dataframes as CSV files
demographics_df.to_csv('cleaned_demographics.csv', index=False)
transaction_history_df.to_csv('cleaned_transaction_history.csv', index=False)
website_interactions_df.to_csv('cleaned_website_interactions.csv', index=False)
social_media_engagements_df.to_csv('cleaned_social_media_engagements.csv', index=False)
customer_feedback_df.to_csv('cleaned_customer_feedback.csv', index=False)

import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Assuming you have already cleaned and preprocessed dataframes
# Use the cleaned data from previous steps
# demographics_df, transaction_history_df, website_interactions_df,
# social_media_engagements_df, customer_feedback_df

# Example feature engineering for demographics data
# Creating a new feature 'age_group' based on age
demographics_df['age_group'] = pd.cut(demographics_df['age'], bins=[0, 30, 50, float('inf')], labels=['Young', 'Middle-aged', 'Senior'])

# Example feature engineering for transaction history data
# Calculating average transaction amount per customer
avg_transaction_amount = transaction_history_df.groupby('customer_id')['amount'].mean()
demographics_df = demographics_df.merge(avg_transaction_amount, on='customer_id', how='left')
demographics_df.rename(columns={'amount': 'avg_transaction_amount'}, inplace=True)
demographics_df['avg_transaction_amount'].fillna(0, inplace=True)  # Handle missing values if any

# Example feature engineering for website interactions data
# Scaling numerical features using StandardScaler
numerical_features = ['page_views', 'clicks']
scaler = StandardScaler()
website_interactions_df[numerical_features] = scaler.fit_transform(website_interactions_df[numerical_features])

# Example feature engineering for social media engagements data
# Encoding categorical variable 'gender' using OneHotEncoder
encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
encoded_gender = encoder.fit_transform(demographics_df[['gender']])

# Get feature names for encoded gender
gender_categories = encoder.categories_[0]
encoded_gender_df = pd.DataFrame(encoded_gender, columns=[f'gender_{category}' for category in gender_categories])

# Concatenate encoded gender back to demographics_df
demographics_df = pd.concat([demographics_df, encoded_gender_df], axis=1)

# Display updated demographics data after feature engineering
print("\nUpdated Demographics Data with Engineered Features:\n", demographics_df)

# Example pipeline for preprocessing numerical and categorical features
# This can be extended based on your specific feature engineering needs
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(), ['gender'])
    ])

# Fit and transform the data
# Adjust column selection based on the columns available in demographics_df
processed_data = preprocessor.fit_transform(demographics_df[['page_views', 'clicks', 'gender']])

# Display processed data
processed_df = pd.DataFrame(processed_data, columns=numerical_features + list(encoder.get_feature_names(['gender'])))
print("\nProcessed Data:\n", processed_df)

import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Example data creation
demographics_data = {
    'customer_id': [1, 2, 3, 4],
    'age': [25, 30, 47, 29],
    'gender': ['F', 'M', 'F', 'M'],
    'income': [50000, 60000, 55000, 72000],
    'page_views': [5, 3, 4, 2],
    'clicks': [10, 15, 8, 5]
}

# Convert to DataFrame
demographics_df = pd.DataFrame(demographics_data)

# Display original data
print("Original Demographics Data:\n", demographics_df)

# Example feature engineering
# Assume you have already scaled 'page_views' and 'clicks' and encoded 'gender' if needed

# Example pipeline for preprocessing numerical and categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['page_views', 'clicks']),
        ('cat', OneHotEncoder(), ['gender'])
    ])

# Fit and transform the data
# Adjust column selection based on the columns available in demographics_df
processed_data = preprocessor.fit_transform(demographics_df[['page_views', 'clicks', 'gender']])

# Display processed data
processed_df = pd.DataFrame(processed_data, columns=['scaled_page_views', 'scaled_clicks', 'gender_F', 'gender_M'])
print("\nProcessed Data:\n", processed_df)

import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# Example data creation
demographics_data = {
    'customer_id': [1, 2, 3, 4],
    'age': [25, 30, 47, 29],
    'gender': ['F', 'M', 'F', 'M'],
    'income': [50000, 60000, 55000, 72000],
    'page_views': [5, 3, 4, 2],
    'clicks': [10, 15, 8, 5]
}

# Convert to DataFrame
demographics_df = pd.DataFrame(demographics_data)

# Display original data
print("Original Demographics Data:\n", demographics_df)

# Example feature engineering
# Creating a new feature 'age_group' based on age
demographics_df['age_group'] = pd.cut(demographics_df['age'], bins=[0, 30, 50, float('inf')], labels=['Young', 'Middle-aged', 'Senior'])

# Scaling numerical features using StandardScaler
numerical_features = ['page_views', 'clicks']
scaler = StandardScaler()
demographics_df[numerical_features] = scaler.fit_transform(demographics_df[numerical_features])

# Encoding categorical variable 'gender' using OneHotEncoder
encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')

# Define a ColumnTransformer to handle preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', scaler, numerical_features),  # Scale numerical features
        ('cat', encoder, ['gender'])         # Encode categorical feature 'gender'
    ], remainder='passthrough')  # Remainder='passthrough' to keep non-transformed columns

# Fit and transform the data
processed_data = preprocessor.fit_transform(demographics_df[['gender'] + numerical_features])

# Get feature names for numerical features and encoded categorical feature 'gender'
feature_names = numerical_features + list(encoder.get_feature_names(['gender']))

# Create processed DataFrame
processed_df = pd.DataFrame(processed_data, columns=feature_names)

# Concatenate other features (age_group, income, etc.) to processed_df
processed_df = pd.concat([processed_df, demographics_df[['age_group', 'income']]], axis=1)

# Display processed data
print("\nProcessed Data:\n", processed_df)

import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# Example data creation
demographics_data = {
    'customer_id': [1, 2, 3, 4],
    'age': [25, 30, 47, 29],
    'gender': ['F', 'M', 'F', 'M'],
    'income': [50000, 60000, 55000, 72000],
    'page_views': [5, 3, 4, 2],
    'clicks': [10, 15, 8, 5]
}

# Convert to DataFrame
demographics_df = pd.DataFrame(demographics_data)

# Display original data
print("Original Demographics Data:\n", demographics_df)

# Example feature engineering
# Creating a new feature 'age_group' based on age
demographics_df['age_group'] = pd.cut(demographics_df['age'], bins=[0, 30, 50, float('inf')], labels=['Young', 'Middle-aged', 'Senior'])

# Scaling numerical features using StandardScaler
numerical_features = ['page_views', 'clicks']
scaler = StandardScaler()
demographics_df[numerical_features] = scaler.fit_transform(demographics_df[numerical_features])

# Encoding categorical variable 'gender' using OneHotEncoder
encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')

# Fit and transform the categorical variable
encoded_gender = encoder.fit_transform(demographics_df[['gender']])

# Get feature names for the encoded categorical feature 'gender'
gender_categories = demographics_df['gender'].unique()
encoded_gender_feature_names = [f'gender_{category}' for category in gender_categories]

# Combine numerical and encoded categorical feature names
feature_names = numerical_features + encoded_gender_feature_names

# Create processed DataFrame
processed_data = pd.DataFrame(
    data = pd.concat([pd.DataFrame(encoded_gender), demographics_df[numerical_features]], axis=1),
    columns = feature_names
)

# Concatenate other features (age_group, income, etc.) to processed_df
processed_df = pd.concat([processed_data, demographics_df[['age_group', 'income']]], axis=1)

# Display processed data
print("\nProcessed Data:\n", processed_df)

# Assuming processed_df contains your final processed data
processed_df.to_csv('processed_data.csv', index=False)

demographics_df.to_csv('demographics_data_processed.csv', index=False)